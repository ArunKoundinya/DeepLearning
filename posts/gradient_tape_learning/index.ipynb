{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Basic Tensor Gradient Tape \n",
        "categories:\n",
        "- Tensor Basics\n",
        "- Gradient Tape\n",
        "date: '2024-04-21'\n",
        "draft: false\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This blog has been created out of curiosity to develop gradient descent from scratch rather than using the gradient descent algorithm directly.\n",
        "\n",
        "This has been a good learning experience for me, and I have created it as a blog post for both my future reference and for sharing what I've learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](gradientdescent.jpeg){fig-align=\"center\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArunKoundinya/DeepLearning/blob/main/posts/gradient_tape_learning/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e9Ev5HSjMg2Z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. First Derivative (At one point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1. First Derivate for single variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k0980HUGMrlF"
      },
      "outputs": [],
      "source": [
        "x = tf.constant(100.0)\n",
        "b = tf.constant(10.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  y = x ** 2 + b\n",
        "  dy_dx = tape.gradient(y, x)\n",
        "\n",
        "del tape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oOSmccROBEX",
        "outputId": "12517744-2695-4d5d-cb67-09749d1d078c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(200.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(dy_dx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For equation `x**2 +b` the first derivate at point where `x=100` is `200`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2. First Derivate with two variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khKy0PeFEnbb",
        "outputId": "44e0a462-8036-492a-c498-b237eaf0e3ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
          ]
        }
      ],
      "source": [
        "x = tf.constant(20.0)\n",
        "b = tf.constant(10.0)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  tape.watch(x)\n",
        "  tape.watch(b)\n",
        "  y = x ** 2 + b ** 2\n",
        "  dy_dx = tape.gradient(y, x)\n",
        "  dy_db = tape.gradient(y, b)\n",
        "\n",
        "del tape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqR403pmNTE3",
        "outputId": "508be824-b9e5-4273-9342-9c4e0db971ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(40.0, shape=(), dtype=float32)\n",
            "tf.Tensor(20.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(dy_dx)\n",
        "print(dy_db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For equation `x**2 + b**2` the first derivate at point where `x=20` is `40` and where `b=10` is `20`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3. First Derivate with two variables - Simpler Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.3.1. Using tf.constant - No output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We when remove `tape.watch(x)` it is important for us to define as `tf.Variable` as gradient needs to be calculated iteratively at that point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DsZBBCrNNzQR"
      },
      "outputs": [],
      "source": [
        "x = tf.constant(20.0)\n",
        "b = tf.constant(10.0)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    y = x ** 2 + b ** 2\n",
        "dy_dx, dy_db = tape.gradient(y, [x, b])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IbwV3SHQNT2",
        "outputId": "e1b4a652-912e-4222-945d-b7de72cd8ab8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(dy_dx)\n",
        "print(dy_db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.3.2. Using tf.Variable - Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also, using simpler code we can see we can pass variables in a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CB_acEWCDmJp"
      },
      "outputs": [],
      "source": [
        "x = tf.Variable(20.0)\n",
        "b = tf.Variable(10.0)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    y = x ** 2 + b ** 2\n",
        "dy_dx, dy_db = tape.gradient(y, [x, b])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1ChrU4IHNKW",
        "outputId": "127ce159-9fb9-4475-a3f7-be8dfdbf4fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(40.0, shape=(), dtype=float32)\n",
            "tf.Tensor(20.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(dy_dx)\n",
        "print(dy_db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Second Derivate using one variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1. Wrong indentation of code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The issue with the below is code is about code `indentation` when we need to calculate second derivative. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4zlvWHfHIl_h"
      },
      "outputs": [],
      "source": [
        "x = tf.Variable(20.0)\n",
        "b = tf.Variable(10.0)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape2:\n",
        "  with tf.GradientTape(persistent=True) as tape1:\n",
        "    y = x ** 2 + b ** 2\n",
        "dy_dx = tape1.gradient(y, x)\n",
        "dy_dx_1 = tape2.gradient(dy_dx, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmOCaG5rI5_i",
        "outputId": "a5d7cd5b-05b4-4050-fb88-bb0e622789ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(40.0, shape=(), dtype=float32)\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(dy_dx)\n",
        "print(dy_dx_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. With right indentation of code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "loUsqUA6I7sd"
      },
      "outputs": [],
      "source": [
        "x = tf.Variable(20.0)\n",
        "b = tf.Variable(10.0)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape2:\n",
        "  with tf.GradientTape(persistent=True) as tape1:\n",
        "    y = x ** 2 + b ** 2\n",
        "  dy_dx = tape1.gradient(y, x)\n",
        "dy_dx_1 = tape2.gradient(dy_dx, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VEn8mM3Jc5T",
        "outputId": "6fe7d1f9-b82d-4ba7-ad86-42fb3ebf3e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(40.0, shape=(), dtype=float32)\n",
            "tf.Tensor(2.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(dy_dx)\n",
        "print(dy_dx_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For equation `x**2 + b**2` the first derivate at point where `x=20` is `40` and where `b=10` is `20`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3. Second Order Derivate for array of numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JBH7WUkgx40n"
      },
      "outputs": [],
      "source": [
        "x = tf.Variable([-3,-2,-1,0,1,2,3],dtype=tf.float32)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape2:\n",
        "  with tf.GradientTape(persistent=True) as tape1:\n",
        "    y = tf.math.square(x)\n",
        "  dy_dx = tape1.gradient(y, x)\n",
        "dy_dx_1 = tape2.gradient(dy_dx, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ziubpfm2yl-d",
        "outputId": "675f7d56-9b2e-4c32-a6af-534dde764c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([-6. -4. -2.  0.  2.  4.  6.], shape=(7,), dtype=float32)\n",
            "tf.Tensor([2. 2. 2. 2. 2. 2. 2.], shape=(7,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(dy_dx)\n",
        "print(dy_dx_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.0 Gradient Descent Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](gradientdescent.jpeg){fig-align=\"center\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we will try to create a `gradient descent function` which will iterative to calculate the derivate and update the weights as per the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "7P3flHPF0mgt"
      },
      "outputs": [],
      "source": [
        "def gradientdescent(learning_rate, w0):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y = tf.math.square(w0)\n",
        "\n",
        "  dy_dw0 = tape.gradient(y, w0)\n",
        "  w0 = w0 - learning_rate * dy_dw0\n",
        "  return w0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "lAR8a8GM30Oc"
      },
      "outputs": [],
      "source": [
        "w0 = tf.Variable(1.0,dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we are running for `10k` epochs to arrive at the minimal value given the function `y = x^2` which is nothing but a `parabola`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "DRbVu9-A4fEp"
      },
      "outputs": [],
      "source": [
        "for i in range(10000):\n",
        "  w0 = tf.Variable(gradientdescent(0.01,w0).numpy(),dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4-8H_lR5Ini",
        "outputId": "582cb5db-6301-414b-f4af-5407edb169a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.803526e-37"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w0.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After running for `10K` epochs we can clearly observe how we have arrived at almost `0` value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "w0 = tf.Variable(1.0,dtype=tf.float32)\n",
        "\n",
        "weights = []\n",
        "for i in range(10000):\n",
        "  weights.append(w0.numpy())\n",
        "  w0 = tf.Variable(gradientdescent(0.01,w0).numpy(),dtype=tf.float32)\n",
        "  \n",
        "import pandas as pd\n",
        "from plotnine import *\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "df = pd.DataFrame({'epoch': range(10000), 'w0': weights})\n",
        "\n",
        "# Plot the data using ggplot\n",
        "(ggplot(df, aes(x='epoch', y='w0'))\n",
        " + geom_line()\n",
        " + labs(title='w0 over epochs', x='Epoch', y='w0')\n",
        " + theme_minimal())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](plotnine_epochs_trend.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see clearly how we have successfully performed gradient descent for a toy example"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO8+Amxu0FA0c5OUmNrmjjg",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
